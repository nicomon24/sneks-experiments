{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Agent Snek\n",
    "In this notebook, we want to analyze the performances, critical features and results for the single agent environment.\n",
    "\n",
    "## Draft roadmap\n",
    "- Loading and rendering of the environment on notebook (save on GIF)\n",
    "- Optimal solution performance and rendering\n",
    "- DQN experiments\n",
    "    - Network size\n",
    "    - Learnt model visual reconstruction\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML, Image\n",
    "from IPython import display\n",
    "import gym, sneks\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('snek-rgb-16-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_episode(env, policy):\n",
    "    obs = env.reset()\n",
    "    observations, done, steps, reward = [obs], False, 0, 0\n",
    "    while not done:\n",
    "        obs, r, done, _ = env.step(policy(obs))\n",
    "        reward += r\n",
    "        steps += 1\n",
    "        observations.append(obs)\n",
    "    return observations, steps, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode return: -1\n",
      "Episode length: 10\n"
     ]
    }
   ],
   "source": [
    "observations, steps, reward = play_one_episode(env, lambda x: env.action_space.sample())\n",
    "print(\"Episode return:\", reward)\n",
    "print(\"Episode length:\", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifs/test_env.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def saveualize(observations, filepath):\n",
    "    fig, ax = plt.subplots(1, figsize=(6, 6))\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "    img = ax.imshow(observations[0])\n",
    "\n",
    "    def animate(i):\n",
    "        img.set_data(observations[i])\n",
    "        return img\n",
    "\n",
    "    plt.axis('off')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(observations), interval=1000);\n",
    "    anim.save(filepath, writer='imagemagick', fps=15)\n",
    "    return Image(url=filepath, format='gif')\n",
    "\n",
    "display.display(saveualize(observations, 'gifs/test_env.gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from basic.benchmark import BasicPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode return: -1\n",
      "Episode length: 11\n"
     ]
    }
   ],
   "source": [
    "pi = BasicPolicy()\n",
    "observations, steps, reward = play_one_episode(env, lambda x: pi.act(x))\n",
    "print(\"Episode return:\", reward)\n",
    "print(\"Episode length:\", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifs/basic_policy.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(saveualize(observations, 'gifs/basic_policy.gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN policy - Small architecture\n",
    "- CONV: (64, 4, 1)\n",
    "- LINEAR: 256\n",
    "- 1e7 timesteps\n",
    "- 1e5 experience replay capacity\n",
    "- 1e4 init timesteps\n",
    "- epsilon from 1.0 to 0.02 on 1e5 timesteps\n",
    "- update target net each 1000 timesteps\n",
    "- batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create env for pytorch\n",
    "from common.atari_wrappers import ScaledFloatFrame\n",
    "from common.pytorch_utils import ImageToPyTorch\n",
    "def make_env(env_name, rnd_seed):\n",
    "    env = gym.make(env_name)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env.seed(rnd_seed)\n",
    "    return env\n",
    "\n",
    "env = make_env('snek-rgb-16-v1', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Qnetwork\n",
    "import torch\n",
    "from dqn.qnetwork import QNetwork\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state = torch.load('../smally_base.pth', map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = QNetwork(env.observation_space, env.action_space, arch=state['arch'], dueling=state.get('dueling', False)).to(device)\n",
    "net.load_state_dict(state['state_dict'])\n",
    "\n",
    "def q_act(obs):\n",
    "    action = net(torch.from_numpy(np.expand_dims(obs, 0)).to(device)).argmax(dim=1)[0]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode return: 28\n",
      "Episode length: 750\n"
     ]
    }
   ],
   "source": [
    "observations, steps, reward = play_one_episode(env, q_act)\n",
    "print(\"Episode return:\", reward)\n",
    "print(\"Episode length:\", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape observations for matplotlib\n",
    "observations = [np.transpose(obs, (1, 2, 0)) for obs in observations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifs/qsmall.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(saveualize(observations, 'gifs/qsmall.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
