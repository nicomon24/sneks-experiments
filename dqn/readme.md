# DQN

In this section, we explore solutions for the single agent Snek environment using DQN based algorithms. We start from the DQN implementation of [PTAN](https://github.com/Shmuma/ptan).

We include different scripts:
- *train.py*: train on a given environment using DQN
- *train_sacred.py*: train but using sacred to keep track of results
- *play.py*: use a trained network to play episodes and export replays.

A commentary and analysis of results can be found @ [my personal blog post](www.google.com).
